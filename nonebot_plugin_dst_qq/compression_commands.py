"""
æ•°æ®å‹ç¼©å’Œå½’æ¡£ç®¡ç†å‘½ä»¤

æä¾›å®Œæ•´çš„æ•°æ®å‹ç¼©å’Œå½’æ¡£åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- æ•°æ®å¤§å°åˆ†æ
- è‡ªåŠ¨å‹ç¼©ç®¡ç†
- å½’æ¡£æ–‡ä»¶ç®¡ç†
- å‹ç¼©ç»Ÿè®¡æŸ¥çœ‹
"""

from nonebot import on_command
from nonebot.adapters import Event
from nonebot.adapters.onebot.v11 import Bot
from nonebot.permission import SUPERUSER
from nonebot.log import logger
from datetime import datetime, timedelta

from .data_archive_manager import archive_manager


# æ•°æ®åˆ†æå‘½ä»¤
data_analysis_cmd = on_command(
    "æ•°æ®åˆ†æ", aliases={"dataanalysis", "æ•°æ®å¤§å°", "æ•°æ®ç»Ÿè®¡"}, 
    permission=SUPERUSER, priority=1, block=True
)

# å‹ç¼©å‘½ä»¤
compress_data_cmd = on_command(
    "å‹ç¼©æ•°æ®", aliases={"compress", "æ•°æ®å‹ç¼©"}, 
    permission=SUPERUSER, priority=1, block=True
)

# å½’æ¡£å‘½ä»¤
archive_data_cmd = on_command(
    "å½’æ¡£æ•°æ®", aliases={"archive", "æ•°æ®å½’æ¡£"}, 
    permission=SUPERUSER, priority=1, block=True
)

# è‡ªåŠ¨å‹ç¼©å‘½ä»¤
auto_compress_cmd = on_command(
    "è‡ªåŠ¨å‹ç¼©", aliases={"autocompress", "æ‰¹é‡å‹ç¼©"}, 
    permission=SUPERUSER, priority=1, block=True
)

# è‡ªåŠ¨å½’æ¡£å‘½ä»¤
auto_archive_cmd = on_command(
    "è‡ªåŠ¨å½’æ¡£", aliases={"autoarchive", "æ‰¹é‡å½’æ¡£"}, 
    permission=SUPERUSER, priority=1, block=True
)

# å‹ç¼©ç»Ÿè®¡å‘½ä»¤
compression_stats_cmd = on_command(
    "å‹ç¼©ç»Ÿè®¡", aliases={"compressionstats", "å‹ç¼©çŠ¶æ€"}, 
    permission=SUPERUSER, priority=1, block=True
)

# æ¸…ç†å½’æ¡£å‘½ä»¤
cleanup_archives_cmd = on_command(
    "æ¸…ç†å½’æ¡£", aliases={"cleanuparchives", "å½’æ¡£æ¸…ç†"}, 
    permission=SUPERUSER, priority=1, block=True
)

# æŸ¥çœ‹å½’æ¡£å‘½ä»¤
view_archives_cmd = on_command(
    "æŸ¥çœ‹å½’æ¡£", aliases={"listarchives", "å½’æ¡£åˆ—è¡¨"}, 
    permission=SUPERUSER, priority=1, block=True
)

# æ•°æ®ç»´æŠ¤å‘½ä»¤
data_maintenance_cmd = on_command(
    "æ•°æ®ç»´æŠ¤", aliases={"maintenance", "æ•°æ®æ•´ç†"}, 
    permission=SUPERUSER, priority=1, block=True
)


@data_analysis_cmd.handle()
async def handle_data_analysis(bot: Bot, event: Event):
    """æ•°æ®å¤§å°å’Œåˆ†å¸ƒåˆ†æ"""
    try:
        await bot.send(event, "ğŸ” æ­£åœ¨åˆ†ææ•°æ®åº“å¤§å°å’Œåˆ†å¸ƒ...")
        
        stats = await archive_manager.analyze_data_size()
        
        if not stats:
            await bot.send(event, "âŒ åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“è¿æ¥")
            return
        
        response = "ğŸ“Š æ•°æ®åº“åˆ†ææŠ¥å‘Š\n\n"
        
        # å½“å‰æ•°æ®ç»Ÿè®¡
        current = stats.get("current_data", {})
        response += "ğŸ“ˆ å½“å‰æ•°æ®çŠ¶æ€:\n"
        response += f"  ğŸ“ æ€»è®°å½•æ•°: {current.get('total_records', 0):,}\n"
        response += f"  ğŸ’¾ æ–‡ä»¶å¤§å°: {current.get('file_size_mb', 0)} MB\n"
        response += f"  ğŸ“ å­˜å‚¨è·¯å¾„: ~/.local/share/nonebot2/data/\n\n"
        
        # æ•°æ®åˆ†å¸ƒ
        daily_dist = stats.get("daily_distribution", [])[:10]
        if daily_dist:
            response += "ğŸ“… æœ€è¿‘10å¤©æ•°æ®åˆ†å¸ƒ:\n"
            for item in daily_dist:
                response += f"  {item['date']}: {item['records']:,} æ¡\n"
            response += "\n"
        
        # é›†ç¾¤åˆ†å¸ƒ
        cluster_dist = stats.get("cluster_distribution", [])[:5]
        if cluster_dist:
            response += "ğŸ® é›†ç¾¤æ•°æ®åˆ†å¸ƒ (å‰5å):\n"
            for item in cluster_dist:
                response += f"  {item['cluster']}/{item['world']}: {item['records']:,} æ¡\n"
            response += "\n"
        
        # å‹ç¼©æœºä¼šåˆ†æ
        compression = stats.get("compression_opportunities", {})
        response += "âš¡ å‹ç¼©ä¼˜åŒ–åˆ†æ:\n"
        response += f"  ğŸ—œï¸ å¯å‹ç¼©è®°å½•: {compression.get('compressible_records', 0):,} æ¡\n"
        response += f"  ğŸ“¦ å¯å½’æ¡£è®°å½•: {compression.get('archivable_records', 0):,} æ¡\n"
        response += f"  ğŸ’° é¢„è®¡èŠ‚çœç©ºé—´: {compression.get('estimated_space_saving_mb', 0)} MB\n\n"
        
        # å·²å‹ç¼©æ•°æ®
        compressed = stats.get("compressed_data", {})
        if compressed.get("compressed_batches", 0) > 0:
            response += "ğŸ—œï¸ å·²å‹ç¼©æ•°æ®:\n"
            response += f"  ğŸ“¦ å‹ç¼©æ‰¹æ¬¡: {compressed['compressed_batches']}\n"
            response += f"  ğŸ“ å‹ç¼©è®°å½•: {compressed['compressed_records']:,} æ¡\n"
            response += f"  ğŸ’¾ å‹ç¼©å¤§å°: {compressed['compressed_size_bytes'] / (1024*1024):.2f} MB\n\n"
        
        # å·²å½’æ¡£æ•°æ®
        archived = stats.get("archived_data", {})
        if archived.get("archived_batches", 0) > 0:
            response += "ğŸ“ å·²å½’æ¡£æ•°æ®:\n"
            response += f"  ğŸ“¦ å½’æ¡£æ‰¹æ¬¡: {archived['archived_batches']}\n"
            response += f"  ğŸ“ å½’æ¡£è®°å½•: {archived['archived_records']:,} æ¡\n"
            response += f"  ğŸ’¾ å½’æ¡£å¤§å°: {archived['archived_size_bytes'] / (1024*1024):.2f} MB\n\n"
        
        # ä¼˜åŒ–å»ºè®®
        total_records = current.get('total_records', 0)
        if total_records > 50000:
            response += "ğŸ’¡ ä¼˜åŒ–å»ºè®®:\n"
            response += "  ğŸ”§ å»ºè®®æ‰§è¡Œè‡ªåŠ¨å‹ç¼©ä»¥é‡Šæ”¾ç©ºé—´\n"
            response += "  ğŸ“¦ å»ºè®®å®šæœŸå½’æ¡£æ—§æ•°æ®\n"
            response += "  âš™ï¸ å¯è°ƒæ•´å‹ç¼©ç­–ç•¥ä»¥è·å¾—æ›´å¥½æ•ˆæœ\n"
        elif compression.get('compressible_records', 0) > 1000:
            response += "ğŸ’¡ ä¼˜åŒ–å»ºè®®:\n"
            response += "  ğŸ”§ å¯ä»¥æ‰§è¡Œæ•°æ®å‹ç¼©ä»¥èŠ‚çœç©ºé—´\n"
        else:
            response += "âœ… æ•°æ®åº“çŠ¶æ€è‰¯å¥½ï¼Œæš‚æ— éœ€ä¼˜åŒ–\n"
        
        await bot.send(event, response)
        
    except Exception as e:
        error_msg = f"âŒ æ•°æ®åˆ†æå¤±è´¥: {str(e)}"
        logger.error(error_msg)
        await bot.send(event, error_msg)


@compress_data_cmd.handle()
async def handle_compress_data(bot: Bot, event: Event):
    """æ‰‹åŠ¨å‹ç¼©æŒ‡å®šæ—¥æœŸæ•°æ®"""
    try:
        # è·å–å‘½ä»¤å‚æ•°
        message_text = str(event.get_message()).strip()
        args = message_text.split()
        
        if len(args) < 2:
            await bot.send(event, "ğŸ’¡ ç”¨æ³•: å‹ç¼©æ•°æ® <æ—¥æœŸ>\nä¾‹å¦‚: å‹ç¼©æ•°æ® 2024-01-15")
            return
        
        target_date = args[1]
        
        # éªŒè¯æ—¥æœŸæ ¼å¼
        try:
            datetime.strptime(target_date, "%Y-%m-%d")
        except ValueError:
            await bot.send(event, "âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
            return
        
        await bot.send(event, f"ğŸ—œï¸ æ­£åœ¨å‹ç¼© {target_date} çš„æ•°æ®...")
        
        result = await archive_manager.compress_daily_data(target_date)
        
        if result["success"]:
            response = f"âœ… æ•°æ®å‹ç¼©å®Œæˆ!\n\n"
            response += f"ğŸ“… å¤„ç†æ—¥æœŸ: {target_date}\n"
            response += f"ğŸ“ å¤„ç†è®°å½•: {result['records_processed']:,} æ¡\n"
            response += f"ğŸ“¦ åŸå§‹å¤§å°: {result['original_size_mb']} MB\n"
            response += f"ğŸ—œï¸ å‹ç¼©å¤§å°: {result['compressed_size_mb']} MB\n"
            response += f"ğŸ“Š å‹ç¼©æ¯”ä¾‹: {result['compression_ratio']:.1%}\n"
            response += f"ğŸ’° èŠ‚çœç©ºé—´: {result['space_saved_mb']} MB\n"
            response += f"â±ï¸ å¤„ç†æ—¶é—´: {result['processing_time_ms']} ms"
        else:
            response = f"âŒ å‹ç¼©å¤±è´¥: {result['message']}"
        
        await bot.send(event, response)
        
    except Exception as e:
        error_msg = f"âŒ æ•°æ®å‹ç¼©å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        await bot.send(event, error_msg)


@archive_data_cmd.handle()
async def handle_archive_data(bot: Bot, event: Event):
    """æ‰‹åŠ¨å½’æ¡£æŒ‡å®šæœˆä»½æ•°æ®"""
    try:
        # è·å–å‘½ä»¤å‚æ•°
        message_text = str(event.get_message()).strip()
        args = message_text.split()
        
        if len(args) < 2:
            await bot.send(event, "ğŸ’¡ ç”¨æ³•: å½’æ¡£æ•°æ® <æœˆä»½>\nä¾‹å¦‚: å½’æ¡£æ•°æ® 2024-01")
            return
        
        target_month = args[1]
        
        # éªŒè¯æœˆä»½æ ¼å¼
        try:
            datetime.strptime(target_month + "-01", "%Y-%m-%d")
        except ValueError:
            await bot.send(event, "âŒ æœˆä»½æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ YYYY-MM æ ¼å¼")
            return
        
        await bot.send(event, f"ğŸ“¦ æ­£åœ¨å½’æ¡£ {target_month} çš„æ•°æ®...")
        
        result = await archive_manager.archive_monthly_data(target_month)
        
        if result["success"]:
            response = f"âœ… æ•°æ®å½’æ¡£å®Œæˆ!\n\n"
            response += f"ğŸ“… å½’æ¡£æœˆä»½: {target_month}\n"
            response += f"ğŸ“ å½’æ¡£è®°å½•: {result['records_processed']:,} æ¡\n"
            response += f"ğŸ“ åˆ›å»ºæ–‡ä»¶: {result['archive_files_created']} ä¸ª\n"
            response += f"ğŸ’¾ æ–‡ä»¶å¤§å°: {result['total_file_size_mb']} MB\n"
            response += f"â±ï¸ å¤„ç†æ—¶é—´: {result['processing_time_ms']} ms\n"
            response += f"ğŸ“‚ å­˜å‚¨è·¯å¾„: ~/.local/share/nonebot2/data/.../archives/"
        else:
            response = f"âŒ å½’æ¡£å¤±è´¥: {result['message']}"
        
        await bot.send(event, response)
        
    except Exception as e:
        error_msg = f"âŒ æ•°æ®å½’æ¡£å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        await bot.send(event, error_msg)


@auto_compress_cmd.handle()
async def handle_auto_compress(bot: Bot, event: Event):
    """è‡ªåŠ¨å‹ç¼©æ‰€æœ‰æ—§æ•°æ®"""
    try:
        await bot.send(event, "ğŸ¤– æ­£åœ¨æ‰§è¡Œè‡ªåŠ¨å‹ç¼©ï¼Œè¯·ç¨å€™...")
        
        result = await archive_manager.auto_compress_old_data()
        
        if result["success"]:
            response = f"âœ… è‡ªåŠ¨å‹ç¼©å®Œæˆ!\n\n"
            response += f"ğŸ“… å¤„ç†æ—¥æœŸ: {len(result['dates_processed'])} å¤©\n"
            response += f"ğŸ“ æ€»å¤„ç†è®°å½•: {result['total_records_processed']:,} æ¡\n"
            response += f"ğŸ’° èŠ‚çœç©ºé—´: {result['total_space_saved_mb']} MB\n\n"
            
            # æ˜¾ç¤ºå¤„ç†çš„æ—¥æœŸåˆ—è¡¨ï¼ˆæœ€å¤šæ˜¾ç¤º10ä¸ªï¼‰
            dates_shown = result['dates_processed'][:10]
            if dates_shown:
                response += "ğŸ“‹ å¤„ç†æ—¥æœŸåˆ—è¡¨:\n"
                for date in dates_shown:
                    response += f"  âœ“ {date}\n"
                
                if len(result['dates_processed']) > 10:
                    response += f"  ... å’Œå…¶ä»– {len(result['dates_processed']) - 10} å¤©\n"
            
            if result['total_records_processed'] == 0:
                response = "â„¹ï¸ æ²¡æœ‰éœ€è¦å‹ç¼©çš„æ•°æ®"
        else:
            response = f"âŒ è‡ªåŠ¨å‹ç¼©å¤±è´¥: {result['message']}"
        
        await bot.send(event, response)
        
    except Exception as e:
        error_msg = f"âŒ è‡ªåŠ¨å‹ç¼©å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        await bot.send(event, error_msg)


@auto_archive_cmd.handle()
async def handle_auto_archive(bot: Bot, event: Event):
    """è‡ªåŠ¨å½’æ¡£æ‰€æœ‰æ—§å‹ç¼©æ•°æ®"""
    try:
        await bot.send(event, "ğŸ¤– æ­£åœ¨æ‰§è¡Œè‡ªåŠ¨å½’æ¡£ï¼Œè¯·ç¨å€™...")
        
        result = await archive_manager.auto_archive_old_compressed_data()
        
        if result["success"]:
            response = f"âœ… è‡ªåŠ¨å½’æ¡£å®Œæˆ!\n\n"
            response += f"ğŸ“… å¤„ç†æœˆä»½: {len(result['months_processed'])} ä¸ª\n"
            response += f"ğŸ“ æ€»å½’æ¡£è®°å½•: {result['total_records_processed']:,} æ¡\n"
            response += f"ğŸ’¾ æ–‡ä»¶æ€»å¤§å°: {result['total_file_size_mb']} MB\n\n"
            
            # æ˜¾ç¤ºå¤„ç†çš„æœˆä»½åˆ—è¡¨
            if result['months_processed']:
                response += "ğŸ“‹ å½’æ¡£æœˆä»½åˆ—è¡¨:\n"
                for month in result['months_processed']:
                    response += f"  ğŸ“¦ {month}\n"
            
            if result['total_records_processed'] == 0:
                response = "â„¹ï¸ æ²¡æœ‰éœ€è¦å½’æ¡£çš„å‹ç¼©æ•°æ®"
        else:
            response = f"âŒ è‡ªåŠ¨å½’æ¡£å¤±è´¥: {result['message']}"
        
        await bot.send(event, response)
        
    except Exception as e:
        error_msg = f"âŒ è‡ªåŠ¨å½’æ¡£å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        await bot.send(event, error_msg)


@compression_stats_cmd.handle()
async def handle_compression_stats(bot: Bot, event: Event):
    """æŸ¥çœ‹å‹ç¼©ç»Ÿè®¡ä¿¡æ¯"""
    try:
        stats = await archive_manager.get_compression_stats()
        
        if not stats:
            await bot.send(event, "âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥")
            return
        
        response = "ğŸ“ˆ å‹ç¼©ç³»ç»Ÿç»Ÿè®¡æŠ¥å‘Š\n\n"
        
        # æ“ä½œç»Ÿè®¡
        operation_stats = stats.get("operation_statistics", {})
        if operation_stats:
            response += "ğŸ”§ æ“ä½œç»Ÿè®¡:\n"
            for op_type, op_data in operation_stats.items():
                response += f"  ğŸ“Š {op_type}:\n"
                response += f"    æ“ä½œæ¬¡æ•°: {op_data['operations']}\n"
                response += f"    å¤„ç†è®°å½•: {op_data['total_records']:,} æ¡\n"
                response += f"    åŸå§‹å¤§å°: {op_data['total_original_size_mb']} MB\n"
                response += f"    å‹ç¼©å¤§å°: {op_data['total_compressed_size_mb']} MB\n"
                response += f"    å¹³å‡å‹ç¼©ç‡: {op_data['avg_compression_ratio']:.1%}\n"
                response += f"    å¹³å‡å¤„ç†æ—¶é—´: {op_data['avg_processing_time_ms']:.1f} ms\n\n"
        
        # å½“å‰å‹ç¼©æ•°æ®
        compressed = stats.get("current_compressed", {})
        response += "ğŸ—œï¸ å½“å‰å‹ç¼©æ•°æ®:\n"
        response += f"  ğŸ“¦ å‹ç¼©æ‰¹æ¬¡: {compressed.get('batches', 0)}\n"
        response += f"  ğŸ“ å‹ç¼©è®°å½•: {compressed.get('total_records', 0):,} æ¡\n"
        response += f"  ğŸ’¾ å‹ç¼©å¤§å°: {compressed.get('total_size_mb', 0)} MB\n"
        response += f"  ğŸ“Š å¹³å‡å‹ç¼©ç‡: {compressed.get('avg_compression_ratio', 0):.1%}\n\n"
        
        # å½“å‰å½’æ¡£æ•°æ®
        archived = stats.get("current_archived", {})
        response += "ğŸ“ å½“å‰å½’æ¡£æ•°æ®:\n"
        response += f"  ğŸ“¦ å½’æ¡£æ–‡ä»¶: {archived.get('files', 0)} ä¸ª\n"
        response += f"  ğŸ“ å½’æ¡£è®°å½•: {archived.get('total_records', 0):,} æ¡\n"
        response += f"  ğŸ’¾ å½’æ¡£å¤§å°: {archived.get('total_size_mb', 0)} MB\n\n"
        
        # æœ€è¿‘æ´»åŠ¨
        recent = stats.get("recent_activities", [])[:5]
        if recent:
            response += "ğŸ“‹ æœ€è¿‘æ´»åŠ¨ (æœ€è¿‘5æ¬¡):\n"
            for activity in recent:
                response += f"  ğŸ•’ {activity['timestamp'][:16]}\n"
                response += f"    æ“ä½œ: {activity['operation']} ({activity['date_processed']})\n"
                response += f"    è®°å½•: {activity['records']:,} æ¡\n"
                response += f"    å‹ç¼©ç‡: {activity['ratio']:.1%}\n"
                response += f"    è€—æ—¶: {activity['time_ms']} ms\n\n"
        
        # é…ç½®ä¿¡æ¯
        config = stats.get("configuration", {})
        response += "âš™ï¸ å½“å‰é…ç½®:\n"
        response += f"  ğŸ• å‹ç¼©é˜ˆå€¼: {config.get('compress_after_days', 7)} å¤©\n"
        response += f"  ğŸ“¦ å½’æ¡£é˜ˆå€¼: {config.get('archive_after_days', 30)} å¤©\n"
        response += f"  ğŸ—‘ï¸ ä¿ç•™å‹ç¼©æ•°æ®: {config.get('keep_compressed_days', 90)} å¤©\n"
        response += f"  ğŸ—‘ï¸ ä¿ç•™å½’æ¡£æ•°æ®: {config.get('keep_archived_days', 365)} å¤©"
        
        await bot.send(event, response)
        
    except Exception as e:
        error_msg = f"âŒ è·å–å‹ç¼©ç»Ÿè®¡å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        await bot.send(event, error_msg)


@cleanup_archives_cmd.handle()
async def handle_cleanup_archives(bot: Bot, event: Event):
    """æ¸…ç†è¿‡æœŸå½’æ¡£æ–‡ä»¶"""
    try:
        await bot.send(event, "ğŸ§¹ æ­£åœ¨æ¸…ç†è¿‡æœŸå½’æ¡£æ–‡ä»¶...")
        
        result = await archive_manager.cleanup_old_archives()
        
        if result["success"]:
            response = f"âœ… å½’æ¡£æ¸…ç†å®Œæˆ!\n\n"
            response += f"ğŸ—‘ï¸ åˆ é™¤æ–‡ä»¶: {len(result['cleaned_files'])} ä¸ª\n"
            response += f"ğŸ’° é‡Šæ”¾ç©ºé—´: {result['space_freed_mb']} MB\n\n"
            
            # æ˜¾ç¤ºåˆ é™¤çš„æ–‡ä»¶ï¼ˆæœ€å¤šæ˜¾ç¤º10ä¸ªï¼‰
            files_shown = result['cleaned_files'][:10]
            if files_shown:
                response += "ğŸ“‹ å·²åˆ é™¤æ–‡ä»¶:\n"
                for file_path in files_shown:
                    file_name = file_path.split('/')[-1]
                    response += f"  ğŸ—‘ï¸ {file_name}\n"
                
                if len(result['cleaned_files']) > 10:
                    response += f"  ... å’Œå…¶ä»– {len(result['cleaned_files']) - 10} ä¸ªæ–‡ä»¶\n"
            
            if len(result['cleaned_files']) == 0:
                response = "â„¹ï¸ æ²¡æœ‰éœ€è¦æ¸…ç†çš„è¿‡æœŸå½’æ¡£æ–‡ä»¶"
        else:
            response = f"âŒ æ¸…ç†å¤±è´¥: {result['message']}"
        
        await bot.send(event, response)
        
    except Exception as e:
        error_msg = f"âŒ æ¸…ç†å½’æ¡£å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        await bot.send(event, error_msg)


@view_archives_cmd.handle()
async def handle_view_archives(bot: Bot, event: Event):
    """æŸ¥çœ‹å¯ç”¨çš„å½’æ¡£æ–‡ä»¶åˆ—è¡¨"""
    try:
        archives_info = await archive_manager.list_archives()
        
        if not archives_info["archives"]:
            await bot.send(event, "ğŸ“¦ å½“å‰æ²¡æœ‰å¯ç”¨çš„å½’æ¡£æ–‡ä»¶")
            return
        
        response = f"ğŸ“¦ å½’æ¡£æ–‡ä»¶åˆ—è¡¨ (å…± {len(archives_info['archives'])} ä¸ª):\n\n"
        
        # æŒ‰æ—¥æœŸæ’åºæ˜¾ç¤ºå½’æ¡£
        sorted_archives = sorted(archives_info["archives"], 
                               key=lambda x: x.get("created_date", ""), 
                               reverse=True)
        
        for archive in sorted_archives[:20]:  # åªæ˜¾ç¤ºæœ€è¿‘20ä¸ª
            name = archive.get("name", "æœªçŸ¥")
            size = archive.get("size_mb", 0)
            date = archive.get("created_date", "æœªçŸ¥")
            records = archive.get("records_count", 0)
            
            response += f"ğŸ“ {name}\n"
            response += f"   ğŸ“… åˆ›å»ºæ—¶é—´: {date}\n"
            response += f"   ğŸ“Š è®°å½•æ•°é‡: {records:,} æ¡\n"
            response += f"   ğŸ’¾ æ–‡ä»¶å¤§å°: {size:.2f} MB\n\n"
        
        if len(archives_info["archives"]) > 20:
            response += f"... è¿˜æœ‰ {len(archives_info['archives']) - 20} ä¸ªæ›´æ—©çš„å½’æ¡£æ–‡ä»¶\n"
        
        # æ·»åŠ æ€»ç»Ÿè®¡
        total_size = sum(a.get("size_mb", 0) for a in archives_info["archives"])
        total_records = sum(a.get("records_count", 0) for a in archives_info["archives"])
        
        response += f"\nğŸ“Š æ€»ç»Ÿè®¡:\n"
        response += f"ğŸ’¾ æ€»å¤§å°: {total_size:.2f} MB\n"
        response += f"ğŸ“ æ€»è®°å½•: {total_records:,} æ¡\n"
        
        await bot.send(event, response)
        
    except Exception as e:
        error_msg = f"âŒ æŸ¥çœ‹å½’æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        await bot.send(event, error_msg)


@data_maintenance_cmd.handle()
async def handle_data_maintenance(bot: Bot, event: Event):
    """æ‰§è¡Œå®Œæ•´çš„æ•°æ®ç»´æŠ¤æµç¨‹"""
    try:
        await bot.send(event, "ğŸ”§ å¼€å§‹æ‰§è¡Œæ•°æ®ç»´æŠ¤æµç¨‹...\nè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´")
        
        maintenance_results = []
        
        # 1. è‡ªåŠ¨å‹ç¼©
        await bot.send(event, "1ï¸âƒ£ æ‰§è¡Œè‡ªåŠ¨å‹ç¼©...")
        compress_result = await archive_manager.auto_compress_old_data()
        maintenance_results.append(("å‹ç¼©", compress_result))
        
        # 2. è‡ªåŠ¨å½’æ¡£
        await bot.send(event, "2ï¸âƒ£ æ‰§è¡Œè‡ªåŠ¨å½’æ¡£...")
        archive_result = await archive_manager.auto_archive_old_compressed_data()
        maintenance_results.append(("å½’æ¡£", archive_result))
        
        # 3. æ¸…ç†è¿‡æœŸå½’æ¡£
        await bot.send(event, "3ï¸âƒ£ æ¸…ç†è¿‡æœŸæ–‡ä»¶...")
        cleanup_result = await archive_manager.cleanup_old_archives()
        maintenance_results.append(("æ¸…ç†", cleanup_result))
        
        # æ±‡æ€»ç»“æœ
        response = "âœ… æ•°æ®ç»´æŠ¤å®Œæˆ!\n\n"
        response += "ğŸ“‹ ç»´æŠ¤ç»“æœæ±‡æ€»:\n\n"
        
        total_records = 0
        total_space_saved = 0
        
        for operation, result in maintenance_results:
            if result["success"]:
                response += f"âœ… {operation}æ“ä½œ: æˆåŠŸ\n"
                
                if operation == "å‹ç¼©":
                    records = result.get('total_records_processed', 0)
                    space = result.get('total_space_saved_mb', 0)
                    response += f"  ğŸ“ å¤„ç†è®°å½•: {records:,} æ¡\n"
                    response += f"  ğŸ’° èŠ‚çœç©ºé—´: {space} MB\n"
                    total_records += records
                    total_space_saved += space
                    
                elif operation == "å½’æ¡£":
                    records = result.get('total_records_processed', 0)
                    files = result.get('total_file_size_mb', 0)
                    response += f"  ğŸ“ å½’æ¡£è®°å½•: {records:,} æ¡\n"
                    response += f"  ğŸ’¾ æ–‡ä»¶å¤§å°: {files} MB\n"
                    
                elif operation == "æ¸…ç†":
                    files = len(result.get('cleaned_files', []))
                    space = result.get('space_freed_mb', 0)
                    response += f"  ğŸ—‘ï¸ åˆ é™¤æ–‡ä»¶: {files} ä¸ª\n"
                    response += f"  ğŸ’° é‡Šæ”¾ç©ºé—´: {space} MB\n"
                    total_space_saved += space
                
                response += "\n"
            else:
                response += f"âŒ {operation}æ“ä½œ: å¤±è´¥ - {result.get('message', 'æœªçŸ¥é”™è¯¯')}\n\n"
        
        response += f"ğŸ¯ ç»´æŠ¤æ±‡æ€»:\n"
        response += f"  ğŸ“ æ€»å¤„ç†è®°å½•: {total_records:,} æ¡\n"
        response += f"  ğŸ’° æ€»èŠ‚çœç©ºé—´: {total_space_saved:.2f} MB\n"
        
        # å»ºè®®ä¸‹æ¬¡ç»´æŠ¤æ—¶é—´
        next_maintenance = datetime.now() + timedelta(days=7)
        response += f"  ğŸ“… å»ºè®®ä¸‹æ¬¡ç»´æŠ¤: {next_maintenance.strftime('%Y-%m-%d')}"
        
        await bot.send(event, response)
        
    except Exception as e:
        error_msg = f"âŒ æ•°æ®ç»´æŠ¤å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        await bot.send(event, error_msg)
